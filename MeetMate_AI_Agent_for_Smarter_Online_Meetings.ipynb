{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokshagna28/mokshagna/blob/main/MeetMate_AI_Agent_for_Smarter_Online_Meetings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8AuAGT-9KNm",
        "outputId": "c6254abd-3d34-4cb3-d616-f5598d202804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Connecting to security.ubuntu.com (185.125\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\r                                                                               \rHit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 1s (238 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "100 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai-whisper gradio transformers torch\n",
        "!sudo apt update && sudo apt install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload logo.png, transcript.png, summary.png, actions.png\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "z-UpfkG69N_2",
        "outputId": "956559b6-7f1e-4297-ae7c-ed1544da9a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-530304b7-535f-48a5-99c2-cc2d8a508a6b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-530304b7-535f-48a5-99c2-cc2d8a508a6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1747720284147890326796l836-voicemaker.in-speech.mp3 to 1747720284147890326796l836-voicemaker.in-speech (1).mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simport whisper\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        return f\"[Error in transcription]: {str(e)}\"\n",
        "\n",
        "def summarize_text(text):\n",
        "    try:\n",
        "        chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]\n",
        "        summaries = [summarizer(chunk)[0]['summary_text'] for chunk in chunks]\n",
        "        return \" \".join(summaries)\n",
        "    except Exception as e:\n",
        "        return f\"[Error in summarization]: {str(e)}\"\n",
        "\n",
        "def extract_action_items(text):\n",
        "    try:\n",
        "        actions = re.findall(r\"(?:[A-Z][^.]*\\bwill\\b[^.]*\\.)\", text)\n",
        "        return \"\\n\".join(actions) if actions else \"No clear action items detected.\"\n",
        "    except Exception as e:\n",
        "        return f\"[Error extracting action items]: {str(e)}\"\n",
        "\n",
        "def process_meeting_audio(audio_path):\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    summary = summarize_text(transcript)\n",
        "    actions = extract_action_items(transcript)\n",
        "    return transcript, summary, actions\n",
        "\n",
        "\n",
        "def safe_load_image(path, fallback_text):\n",
        "    try:\n",
        "        return Image.open(path)\n",
        "    except:\n",
        "        print(f\"‚ö†Ô∏è Couldn't load image: {path}\")\n",
        "        return None\n",
        "\n",
        "logo = safe_load_image(\"/content/logo.png\", \"MeetMate\")\n",
        "img_transcript = safe_load_image(\"/content/transcription.webp\", \"Transcript\")\n",
        "img_summary = safe_load_image(\"/content/summary.png\", \"Summary\")\n",
        "img_actions = safe_load_image(\"/content/action.jpg\", \"Action Items\")\n",
        "\n",
        "\n",
        "def handle_audio(audio_path):\n",
        "    transcript, summary, actions = process_meeting_audio(audio_path)\n",
        "    return img_transcript, transcript, img_summary, summary, img_actions, actions\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    if logo:\n",
        "        gr.Image(value=logo, show_label=False)\n",
        "    gr.Markdown(\"## üé§ Upload Your Meeting Audio (.mp3/.wav)\")\n",
        "\n",
        "    # Removed the 'source' argument as it's not accepted by the constructor\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Meeting Audio\")\n",
        "    process_button = gr.Button(\"üöÄ Process Meeting\")\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_1 = gr.Image()\n",
        "        out_transcript = gr.Textbox(label=\"üìù Transcript\", lines=6)\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_2 = gr.Image()\n",
        "        out_summary = gr.Textbox(label=\"üìÑ Summary\", lines=4)\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_3 = gr.Image()\n",
        "        out_actions = gr.Textbox(label=\"‚úÖ Action Items\", lines=4)\n",
        "\n",
        "    process_button.click(fn=handle_audio, inputs=audio_input,\n",
        "                         outputs=[\n",
        "                             out_img_1, out_transcript,\n",
        "                             out_img_2, out_summary,\n",
        "                             out_img_3, out_actions\n",
        "                         ])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Er2KJxPc99o8",
        "outputId": "e8f230ae-4677-4fef-e925-9ed20655c045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e1872dc79ca11f2e7a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e1872dc79ca11f2e7a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = gr.Image(label=\"Optional Image to Include in Email (e.g., Team Photo)\")\n"
      ],
      "metadata": {
        "id": "inQOnvd0k1hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = None # Placeholder: Set this to None or a sample PIL Image object for testing\n",
        "\n",
        "\n",
        "if image is not None:\n",
        "    import base64\n",
        "    import io\n",
        "    buffered = io.BytesIO()\n",
        "    # Ensure the image object is a PIL Image instance before saving\n",
        "    if isinstance(image, Image.Image):\n",
        "        image.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "        image_html = f'<img src=\"data:image/png;base64,{img_str}\" width=\"400\"/>'\n",
        "    else:\n",
        "        # Handle cases where 'image' might be a path or other type if not loaded correctly\n",
        "        print(\"Warning: 'image' variable is not a PIL Image object. Skipping image embedding.\")\n",
        "        image_html = \"\"\n",
        "else:\n",
        "    image_html = \"\"\n",
        "\n",
        "# You can now print image_html to see the result (either the image tag or empty string)\n",
        "print(image_html)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8qSRnXhk2HQ",
        "outputId": "07f51e8b-6dd4-4d95-ec75-fbe6cda66f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "body = f\"\"\"\n",
        "<h2>üìã MeetMate ‚Äì Smart Meeting Report</h2>\n",
        "{image_html}\n",
        "...\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "-jBKpmWzk4Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install -q openai-whisper gradio transformers torch\n",
        "!sudo apt update && sudo apt install -y ffmpeg\n",
        "\n",
        "# %%\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload logo.png, transcript.png, summary.png, actions.png\n",
        "\n",
        "# %%\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        return f\"[Error in transcription]: {str(e)}\"\n",
        "\n",
        "def summarize_text(text):\n",
        "    try:\n",
        "        chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]\n",
        "        summaries = [summarizer(chunk)[0]['summary_text'] for chunk in chunks]\n",
        "        return \" \".join(summaries)\n",
        "    except Exception as e:\n",
        "        return f\"[Error in summarization]: {str(e)}\"\n",
        "\n",
        "def extract_action_items(text):\n",
        "    try:\n",
        "        actions = re.findall(r\"(?:[A-Z][^.]*\\bwill\\b[^.]*\\.)\", text)\n",
        "        return \"\\n\".join(actions) if actions else \"No clear action items detected.\"\n",
        "    except Exception as e:\n",
        "        return f\"[Error extracting action items]: {str(e)}\"\n",
        "\n",
        "def process_meeting_audio(audio_path):\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    summary = summarize_text(transcript)\n",
        "    actions = extract_action_items(transcript)\n",
        "    return transcript, summary, actions\n",
        "\n",
        "\n",
        "def safe_load_image(path, fallback_text):\n",
        "    try:\n",
        "        return Image.open(path)\n",
        "    except:\n",
        "        print(f\"‚ö†Ô∏è Couldn't load image: {path}\")\n",
        "        return None\n",
        "\n",
        "logo = safe_load_image(\"/content/logo.png\", \"MeetMate\")\n",
        "img_transcript = safe_load_image(\"/content/transcription.webp\", \"Transcript\")\n",
        "img_summary = safe_load_image(\"/content/summary.png\", \"Summary\")\n",
        "img_actions = safe_load_image(\"/content/action.jpg\", \"Action Items\")\n",
        "\n",
        "\n",
        "# Modified handle_audio to also return the audio_path\n",
        "def handle_audio(audio_path):\n",
        "    if audio_path is None:\n",
        "        return None, \"\", None, \"\", None, \"\", None\n",
        "    transcript, summary, actions = process_meeting_audio(audio_path)\n",
        "    return img_transcript, transcript, img_summary, summary, img_actions, actions, audio_path\n",
        "\n",
        "# Added a new function to handle the email creation\n",
        "def create_email_attachment(audio_path):\n",
        "    if audio_path is None or not os.path.exists(audio_path):\n",
        "        print(\"No valid audio file path available for attachment.\")\n",
        "        return None\n",
        "\n",
        "    from email.mime.base import MIMEBase\n",
        "    from email import encoders\n",
        "    import os\n",
        "\n",
        "    filename = os.path.basename(audio_path)\n",
        "    try:\n",
        "        with open(audio_path, 'rb') as attachment:\n",
        "            part = MIMEBase('application', 'octet-stream')\n",
        "            part.set_payload(attachment.read())\n",
        "            encoders.encode_base64(part)\n",
        "            part.add_header('Content-Disposition', f\"attachment; filename= {filename}\")\n",
        "            # In a real email scenario, you would attach 'part' to a 'message' object here\n",
        "            print(f\"Successfully created attachment part for {filename}\")\n",
        "            # Return the attachment part (or handle attaching to a message object)\n",
        "            return part\n",
        "    except Exception as e:\n",
        "        print(f\"[Error creating attachment]: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    # Use gr.State to store the audio_path\n",
        "    audio_file_path_state = gr.State(None)\n",
        "\n",
        "    if logo:\n",
        "        gr.Image(value=logo, show_label=False)\n",
        "    gr.Markdown(\"## üé§ Upload Your Meeting Audio (.mp3/.wav)\")\n",
        "\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Meeting Audio\")\n",
        "    process_button = gr.Button(\"üöÄ Process Meeting\")\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_1 = gr.Image()\n",
        "        out_transcript = gr.Textbox(label=\"üìù Transcript\", lines=6)\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_2 = gr.Image()\n",
        "        out_summary = gr.Textbox(label=\"üìÑ Summary\", lines=4)\n",
        "\n",
        "    with gr.Row():\n",
        "        out_img_3 = gr.Image()\n",
        "        out_actions = gr.Textbox(label=\"‚úÖ Action Items\", lines=4)\n",
        "\n",
        "    process_button.click(fn=handle_audio, inputs=audio_input,\n",
        "                         outputs=[\n",
        "                             out_img_1, out_transcript,\n",
        "                             out_img_2, out_summary,\n",
        "                             out_img_3, out_actions,\n",
        "                             audio_file_path_state\n",
        "                         ])\n",
        "\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "image_input = gr.Image(label=\"Optional Image to Include in Email (e.g., Team Photo)\")\n",
        "\n",
        "image = None\n",
        "\n",
        "\n",
        "if image is not None:\n",
        "    import base64\n",
        "    import io\n",
        "    buffered = io.BytesIO()\n",
        "\n",
        "    if isinstance(image, Image.Image):\n",
        "        image.save(buffered, format=\"PNG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "        image_html = f'<img src=\"data:image/png;base64,{img_str}\" width=\"400\"/>'\n",
        "    else:\n",
        "\n",
        "        print(\"Warning: 'image' variable is not a PIL Image object. Skipping image embedding.\")\n",
        "        image_html = \"\"\n",
        "else:\n",
        "    image_html = \"\"\n",
        "\n",
        "\n",
        "print(image_html)\n",
        "\n",
        "\n",
        "body = f\"\"\"\n",
        "<h2>üìã MeetMate ‚Äì Smart Meeting Report</h2>\n",
        "{image_html}\n",
        "...\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dixhrdTmlF5X",
        "outputId": "804cf442-547a-46bf-a5e9-a1aa35175ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 12.7 kB/129\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 54.7 kB/129\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 92.4 kB/129\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connected to r2u.stat.i\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 261 kB in 1s (234 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "100 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-664248d2-322f-4d1a-9ee7-38671e5d29f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-664248d2-322f-4d1a-9ee7-38671e5d29f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving M_0874_15y5m_1.wav to M_0874_15y5m_1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://53c272536fa079f868.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://53c272536fa079f868.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "import os\n",
        "\n",
        "# Load models\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def transcribe_and_summarize(audio, sender_email, app_password, recipients):\n",
        "    # Transcription\n",
        "    # When type=\"filepath\", the 'audio' object provided by Gradio has a 'name' attribute which is the path to the temporary file.\n",
        "    audio_path = audio.name\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    transcript = result[\"text\"]\n",
        "\n",
        "    # Summarization (chunking if needed)\n",
        "    max_chunk = 1000\n",
        "    transcript_chunks = [transcript[i:i+max_chunk] for i in range(0, len(transcript), max_chunk)]\n",
        "    summary = \"\"\n",
        "    for chunk in transcript_chunks:\n",
        "        summary_text = summarizer(chunk, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "        summary += summary_text + \"\\n\"\n",
        "\n",
        "    # Action Item Extraction\n",
        "    action_items = re.findall(r'\\b[A-Z][a-z]+\\b.*?\\b(will|needs to|should)\\b.*?\\.', transcript)\n",
        "    action_list = [item.strip() for item in action_items]\n",
        "\n",
        "    # Send email\n",
        "    send_meeting_email(sender_email, app_password, recipients, \"MeetMate Report\", transcript, summary, action_list, audio_path)\n",
        "\n",
        "    return transcript, summary, action_list\n",
        "\n",
        "def send_meeting_email(sender_email, app_password, recipient_list, subject, transcript, summary, action_items, audio_path):\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_email\n",
        "    message['To'] = \", \".join(recipient_list)\n",
        "    message['Subject'] = subject\n",
        "\n",
        "    body = f\"\"\"\n",
        "    <h2>üìã MeetMate ‚Äì Smart Meeting Report</h2>\n",
        "    <h3>üóíÔ∏è Summary:</h3>\n",
        "    <p>{summary}</p>\n",
        "    <h3>üìù Transcript:</h3>\n",
        "    <p>{transcript}</p>\n",
        "    <h3>‚úÖ Action Items:</h3>\n",
        "    <ul>\n",
        "    {''.join(f\"<li>{item}</li>\" for item in action_items)}\n",
        "    </ul>\n",
        "    <p>Thanks,<br>MeetMate AI Assistant</p>\n",
        "    \"\"\"\n",
        "\n",
        "    message.attach(MIMEText(body, 'html'))\n",
        "\n",
        "    # Attach audio file\n",
        "    try:\n",
        "        filename = os.path.basename(audio_path)\n",
        "        with open(audio_path, 'rb') as attachment:\n",
        "            part = MIMEBase('application', 'octet-stream')\n",
        "            part.set_payload(attachment.read())\n",
        "        encoders.encode_base64(part)\n",
        "        part.add_header('Content-Disposition', f\"attachment; filename= {filename}\")\n",
        "        message.attach(part)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error attaching file: {e}\")\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, app_password)\n",
        "        server.sendmail(sender_email, recipient_list, message.as_string())\n",
        "        server.quit()\n",
        "        print(\"‚úÖ Email sent successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error sending email: {e}\")\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"\"\"# ü§ñ MeetMate ‚Äì AI Agent for Smarter Online Meetings\n",
        "Upload a meeting recording and get the Transcript, Summary, Action Items, and Email Report!\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Changed type=\"file\" to type=\"filepath\"\n",
        "        audio_input = gr.Audio(label=\"/content/M_0874_15y5m_1.mp4\", type=\"filepath\")\n",
        "\n",
        "    with gr.Row():\n",
        "        email_input = gr.Text(label=\"Sender Gmail\")\n",
        "        password_input = gr.Text(label=\"App Password\", type=\"password\")\n",
        "        recipient_input = gr.Text(label=\"Recipient Emails (comma-separated)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn = gr.Button(\"Process and Email Report\")\n",
        "\n",
        "    with gr.Row():\n",
        "        transcript_output = gr.Textbox(label=\"üìÑ Transcript\")\n",
        "        summary_output = gr.Textbox(label=\"üìù Summary\")\n",
        "        action_output = gr.Textbox(label=\"‚úÖ Action Items\")\n",
        "\n",
        "    btn.click(fn=lambda audio, sender, pwd, recs: transcribe_and_summarize(\n",
        "                audio, sender, pwd, [email.strip() for email in recs.split(',')]),\n",
        "              inputs=[audio_input, email_input, password_input, recipient_input],\n",
        "              outputs=[transcript_output, summary_output, action_output])\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "iGQaOc2WlInG",
        "outputId": "db4a5dab-28e5-4fdd-c736-7ef7a5f04366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://57c8f3ee4b4b072ae0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://57c8f3ee4b4b072ae0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# Load models\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "openai.api_key = \"your-openai-api-key\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "# Store transcript globally\n",
        "stored_transcript = \"\"\n",
        "\n",
        "def transcribe_and_summarize(audio, sender_email, app_password, recipients):\n",
        "    global stored_transcript\n",
        "    # Transcription\n",
        "    audio_path = audio.name\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    transcript = result[\"text\"]\n",
        "    stored_transcript = transcript  # Store for Q&A\n",
        "\n",
        "    # Summarization (chunking if needed)\n",
        "    max_chunk = 1000\n",
        "    transcript_chunks = [transcript[i:i+max_chunk] for i in range(0, len(transcript), max_chunk)]\n",
        "    summary = \"\"\n",
        "    for chunk in transcript_chunks:\n",
        "        summary_text = summarizer(chunk, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "        summary += summary_text + \"\\n\"\n",
        "\n",
        "    # Action Item Extraction\n",
        "    action_items = re.findall(r'\\b[A-Z][a-z]+\\b.*?\\b(will|needs to|should)\\b.*?\\.', transcript)\n",
        "    action_list = [item.strip() for item in action_items]\n",
        "\n",
        "    # Send email\n",
        "    send_meeting_email(sender_email, app_password, recipients, \"MeetMate Report\", transcript, summary, action_list, audio_path)\n",
        "\n",
        "    return transcript, summary, action_list\n",
        "\n",
        "def send_meeting_email(sender_email, app_password, recipient_list, subject, transcript, summary, action_items, audio_path):\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_email\n",
        "    message['To'] = \", \".join(recipient_list)\n",
        "    message['Subject'] = subject\n",
        "\n",
        "    body = f\"\"\"\n",
        "    <h2>üìã MeetMate ‚Äì Smart Meeting Report</h2>\n",
        "    <h3>üóíÔ∏è Summary:</h3>\n",
        "    <p>{summary}</p>\n",
        "    <h3>üìù Transcript:</h3>\n",
        "    <p>{transcript}</p>\n",
        "    <h3>‚úÖ Action Items:</h3>\n",
        "    <ul>\n",
        "    {''.join(f\"<li>{item}</li>\" for item in action_items)}\n",
        "    </ul>\n",
        "    <p>Thanks,<br>MeetMate AI Assistant</p>\n",
        "    \"\"\"\n",
        "\n",
        "    message.attach(MIMEText(body, 'html'))\n",
        "\n",
        "    try:\n",
        "        filename = os.path.basename(audio_path)\n",
        "        with open(audio_path, 'rb') as attachment:\n",
        "            part = MIMEBase('application', 'octet-stream')\n",
        "            part.set_payload(attachment.read())\n",
        "        encoders.encode_base64(part)\n",
        "        part.add_header('Content-Disposition', f\"attachment; filename= {filename}\")\n",
        "        message.attach(part)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error attaching file: {e}\")\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, app_password)\n",
        "        server.sendmail(sender_email, recipient_list, message.as_string())\n",
        "        server.quit()\n",
        "        print(\"‚úÖ Email sent successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error sending email: {e}\")\n",
        "\n",
        "def answer_question(question):\n",
        "    global stored_transcript\n",
        "    if not stored_transcript:\n",
        "        return \"Please upload and process a meeting audio first.\"\n",
        "\n",
        "    prompt = f\"Meeting transcript:\\n{stored_transcript}\\n\\nQ: {question}\\nA:\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        answer = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return answer.strip()\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error answering question: {e}\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"\"\"# ü§ñ MeetMate ‚Äì AI Agent for Smarter Online Meetings\n",
        "Upload a meeting recording and get the Transcript, Summary, Action Items, and Email Report!\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Changed type=\"file\" to type=\"filepath\"\n",
        "        audio_input = gr.Audio(label=\"/content/M_0874_15y5m_1.mp4\", type=\"filepath\")\n",
        "\n",
        "    with gr.Row():\n",
        "        email_input = gr.Text(label=\"Sender Gmail\")\n",
        "        password_input = gr.Text(label=\"App Password\", type=\"password\")\n",
        "        recipient_input = gr.Text(label=\"Recipient Emails (comma-separated)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn = gr.Button(\"Process and Email Report\")\n",
        "\n",
        "    with gr.Row():\n",
        "        transcript_output = gr.Textbox(label=\"üìÑ Transcript\")\n",
        "        summary_output = gr.Textbox(label=\"üìù Summary\")\n",
        "        action_output = gr.Textbox(label=\"‚úÖ Action Items\")\n",
        "\n",
        "    with gr.Row():\n",
        "        question_input = gr.Textbox(label=\"Ask a Question about the Meeting\")\n",
        "        answer_output = gr.Textbox(label=\"ü§ñ Answer\")\n",
        "        ask_btn = gr.Button(\"Get Answer\")\n",
        "\n",
        "    btn.click(fn=lambda audio, sender, pwd, recs: transcribe_and_summarize(\n",
        "                audio, sender, pwd, [email.strip() for email in recs.split(',')]),\n",
        "              inputs=[audio_input, email_input, password_input, recipient_input],\n",
        "              outputs=[transcript_output, summary_output, action_output])\n",
        "\n",
        "    ask_btn.click(fn=answer_question, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "75Pkyb8knDw2",
        "outputId": "71dc88e8-6edc-4a35-f2f6-19b9265e08ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://480d93b36abf2b2e36.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://480d93b36abf2b2e36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXJMAXkRoYTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}